{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5df7a8-b9bf-46b1-9009-409284cd2106",
   "metadata": {},
   "source": [
    "#### Module Summary\n",
    "> This module does fine classing of the user edited coarse classing data and creates the summarised fine classing output. Also converts the original development and validation data to their respective WOE bucket values or dummay variables\n",
    "> \n",
    "> **Input Files**\n",
    "> 1. Developemnt and Validation data with reduced features as obtained form 02_coarse_classing module (pickle)\n",
    "> 2. User modified coarse classin data (xlsx)\n",
    "> 3. Feature Readuction Summary (xlsx)\n",
    ">\n",
    "> **Output Files**\n",
    "> 1. Development & Validation data with WOE values/ dummy features (pickle)\n",
    "> 2. Model metadata - will be required for scoring (pickle)\n",
    "> 3. Fine Classing Data (xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c456c5bc-9f45-4b15-96a3-24c719787c27",
   "metadata": {},
   "source": [
    "<h4> 3.1 Import Modules and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86e0741-87fc-4d83-8972-3d383408b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logit_config as cfg\n",
    "exec(open('module_imports.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff5a4d8-ecce-4ba5-8bd0-5b019a488a64",
   "metadata": {},
   "source": [
    "<h4> 3.2 Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb75ba0-1131-498f-92d9-059d14cd8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Model Data Object\n",
    "with open(f\"{outpath}/model_data.pickle\", 'rb') as f:\n",
    "    model_data_pckl_dict = pickle.load(f)\n",
    "dev_data = copy.deepcopy(model_data_pckl_dict['dev_data_out2'])\n",
    "val_data = copy.deepcopy(model_data_pckl_dict['val_data_out2'])\n",
    "\n",
    "# Import Model MetaData Object\n",
    "with open(f\"{outpath}/model_metadata.pickle\", 'rb') as f:\n",
    "    model_metadata_pckl_dict = pickle.load(f)\n",
    "    \n",
    "# Read Manually Edited Coarse Classing Output\n",
    "coarse_classing_df = pd.read_excel(f\"{outpath}/{dev_fname.split('.')[0]}_coarse_classing.xlsx\", sheet_name='coarse_classing_result', skiprows=2, usecols=lambda x: 'Unnamed' not in x)   # Read Excel File\n",
    "coarse_classing_df = coarse_classing_df.dropna(how='all', axis=0).reset_index(drop=True)    # Drop Null Rows\n",
    "dup_header_rowlist = [x for x in range(coarse_classing_df.index.size) if (coarse_classing_df.iloc[x] == coarse_classing_df.columns.tolist()).sum() == len(coarse_classing_df.columns)]\n",
    "coarse_classing_df = coarse_classing_df.drop(dup_header_rowlist)    # Drop Redundant Headers and Unnecessary Columns\n",
    "coarse_classing_df[['TOT_ACTS', 'COUNT_RESP', 'COUNT_NON_RESP']] = coarse_classing_df[['TOT_ACTS', 'COUNT_RESP', 'COUNT_NON_RESP']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca65c03-7ad6-4625-bb09-880106d45cc1",
   "metadata": {},
   "source": [
    "<h4> 3.3 Fine Classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab276be-484c-4652-8c1b-5495f46c5b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.45 s, sys: 108 ms, total: 4.56 s\n",
      "Wall time: 4.61 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR_NAME</th>\n",
       "      <th>BIN_NUM</th>\n",
       "      <th>VAR_BINS</th>\n",
       "      <th>bin_left</th>\n",
       "      <th>bin_right</th>\n",
       "      <th>TOT_ACTS</th>\n",
       "      <th>ROWP_TOT</th>\n",
       "      <th>COUNT_RESP</th>\n",
       "      <th>PER_RESP</th>\n",
       "      <th>COUNT_NON_RESP</th>\n",
       "      <th>PER_NON_RESP</th>\n",
       "      <th>RAW_ODDS</th>\n",
       "      <th>LN_ODDS</th>\n",
       "      <th>INFO_VAL</th>\n",
       "      <th>CH_SQ</th>\n",
       "      <th>RESP_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>1</td>\n",
       "      <td>(-inf, 0.07466]</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.07466</td>\n",
       "      <td>18</td>\n",
       "      <td>0.052786</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.416667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>2</td>\n",
       "      <td>(0.07466, 0.07948]</td>\n",
       "      <td>0.07466</td>\n",
       "      <td>0.07948</td>\n",
       "      <td>17</td>\n",
       "      <td>0.049853</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016</td>\n",
       "      <td>15</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>4.340278</td>\n",
       "      <td>1.467938</td>\n",
       "      <td>0.078453</td>\n",
       "      <td>4.536490</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.07948, 0.08223]</td>\n",
       "      <td>0.07948</td>\n",
       "      <td>0.08223</td>\n",
       "      <td>17</td>\n",
       "      <td>0.049853</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016</td>\n",
       "      <td>15</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>4.340278</td>\n",
       "      <td>1.467938</td>\n",
       "      <td>0.078453</td>\n",
       "      <td>4.536490</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.08223, 0.0842]</td>\n",
       "      <td>0.08223</td>\n",
       "      <td>0.08420</td>\n",
       "      <td>17</td>\n",
       "      <td>0.049853</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032</td>\n",
       "      <td>13</td>\n",
       "      <td>0.060185</td>\n",
       "      <td>1.880787</td>\n",
       "      <td>0.631690</td>\n",
       "      <td>0.017804</td>\n",
       "      <td>1.261702</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>5</td>\n",
       "      <td>(0.0842, 0.08546]</td>\n",
       "      <td>0.08420</td>\n",
       "      <td>0.08546</td>\n",
       "      <td>17</td>\n",
       "      <td>0.049853</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016</td>\n",
       "      <td>15</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>4.340278</td>\n",
       "      <td>1.467938</td>\n",
       "      <td>0.078453</td>\n",
       "      <td>4.536490</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          VAR_NAME BIN_NUM            VAR_BINS  bin_left  bin_right  TOT_ACTS  \\\n",
       "0  smoothness_mean       1     (-inf, 0.07466]      -inf    0.07466        18   \n",
       "1  smoothness_mean       2  (0.07466, 0.07948]   0.07466    0.07948        17   \n",
       "2  smoothness_mean       3  (0.07948, 0.08223]   0.07948    0.08223        17   \n",
       "3  smoothness_mean       4   (0.08223, 0.0842]   0.08223    0.08420        17   \n",
       "4  smoothness_mean       5   (0.0842, 0.08546]   0.08420    0.08546        17   \n",
       "\n",
       "   ROWP_TOT  COUNT_RESP  PER_RESP  COUNT_NON_RESP  PER_NON_RESP  RAW_ODDS  \\\n",
       "0  0.052786           0     0.000              18      0.083333  0.000000   \n",
       "1  0.049853           2     0.016              15      0.069444  4.340278   \n",
       "2  0.049853           2     0.016              15      0.069444  4.340278   \n",
       "3  0.049853           4     0.032              13      0.060185  1.880787   \n",
       "4  0.049853           2     0.016              15      0.069444  4.340278   \n",
       "\n",
       "    LN_ODDS  INFO_VAL      CH_SQ  RESP_RATE  \n",
       "0  0.000000  0.000000  10.416667   0.000000  \n",
       "1  1.467938  0.078453   4.536490   0.117647  \n",
       "2  1.467938  0.078453   4.536490   0.117647  \n",
       "3  0.631690  0.017804   1.261702   0.235294  \n",
       "4  1.467938  0.078453   4.536490   0.117647  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fine_classing_df, dev_data, val_data = fine_classing(dev_data, val_data, coarse_classing_df)\n",
    "fine_classing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80cb01-fc52-4186-b3c6-6845dbab3778",
   "metadata": {},
   "source": [
    "<h4> 3.4 Convert Variable Values - WOE Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a99818a-82a9-45f6-9256-336adc452956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development Variables having missing values: 0\n",
      "Validation Variables having missing values: 0\n",
      "CPU times: user 266 ms, sys: 8.22 ms, total: 275 ms\n",
      "Wall time: 301 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Copy Original Data\n",
    "dev_data_woe = copy.deepcopy(dev_data)\n",
    "val_data_woe = copy.deepcopy(val_data)\n",
    "\n",
    "# Replace Original Data with WOE Values\n",
    "for col in fine_classing_df['VAR_NAME'].drop_duplicates().tolist():\n",
    "    \n",
    "    tmp_woe = fine_classing_df[fine_classing_df['VAR_NAME'] == col][['BIN_NUM', 'LN_ODDS']]\n",
    "    tmp_woe['BIN_NUM'] = tmp_woe['BIN_NUM'].astype(str)\n",
    "    dev_data_woe[col] = dev_data_woe[col].astype(str)\n",
    "    dev_data_woe = dev_data_woe.merge(tmp_woe, left_on=col, right_on='BIN_NUM', how='left')\n",
    "    dev_data_woe.drop([col, 'BIN_NUM'], axis=1, inplace=True)\n",
    "    dev_data_woe.rename(columns={'LN_ODDS': 'L_'+col}, inplace=True)\n",
    "    \n",
    "    val_data_woe[col] = val_data_woe[col].astype(str)\n",
    "    val_data_woe = val_data_woe.merge(tmp_woe, left_on=col, right_on='BIN_NUM', how='left')\n",
    "    val_data_woe.drop([col, 'BIN_NUM'], axis=1, inplace=True)\n",
    "    val_data_woe.rename(columns={'LN_ODDS': 'L_'+col}, inplace=True)\n",
    "    \n",
    "# Check and Replace Missing Values\n",
    "nmiss_dev_df = pd.DataFrame(dev_data_woe.isnull().sum().rename('nmiss')).rename_axis('feature').reset_index()\n",
    "print(f\"Development Variables having missing values: {nmiss_dev_df[nmiss_dev_df['nmiss']>0].index.size}\")\n",
    "\n",
    "nmiss_val_df = pd.DataFrame(val_data_woe.isnull().sum().rename('nmiss')).rename_axis('feature').reset_index()\n",
    "nmiss_mode_df = dev_data_woe[nmiss_val_df[nmiss_val_df['nmiss']>0]['feature'].tolist()].mode()\n",
    "val_data_woe.fillna({col: nmiss_mode_df[col][0] for col in nmiss_val_df[nmiss_val_df['nmiss']>0]['feature'].tolist()}, inplace=True)\n",
    "nmiss_val_df = pd.DataFrame(val_data_woe.isnull().sum().rename('nmiss')).rename_axis('feature').reset_index()\n",
    "print(f\"Validation Variables having missing values: {nmiss_val_df[nmiss_val_df['nmiss']>0].index.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49dd76b3-c6d3-47ed-b9f8-6d2d86e08204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export WOE Data\n",
    "model_data_pckl_dict['dev_data_woe'] = dev_data_woe\n",
    "model_data_pckl_dict['val_data_woe'] = val_data_woe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12932ad1-eeeb-4231-a0c1-94d2764ffb57",
   "metadata": {},
   "source": [
    "<h4> 3.5 Convert Variable Values - Dummy Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55d0fb4-5292-4a90-a47a-3ea82f539546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364 Dummy Variables Created\n",
      "Starting Correlation Check with 60% cut-off\n",
      "Variables Dropped: 10. Updated Development Data Shape: (341, 356)\n",
      "Development Variables having missing values: 0\n",
      "Validation Variables having missing values: 0\n",
      "CPU times: user 382 ms, sys: 15.9 ms, total: 397 ms\n",
      "Wall time: 449 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create Dummy Variables\n",
    "dev_data_dummy, val_data_dummy, d_ord_enc, d_oh_enc = create_dummy_features(dev_data, val_data, resp_var, id_varlist)\n",
    "\n",
    "# Check for Missing Values\n",
    "nmiss_dev_df = pd.DataFrame(dev_data_dummy.isnull().sum().rename('nmiss')).rename_axis('feature').reset_index()\n",
    "print(f\"Development Variables having missing values: {nmiss_dev_df[nmiss_dev_df['nmiss']>0].index.size}\")\n",
    "\n",
    "nmiss_val_df = pd.DataFrame(val_data_dummy.isnull().sum().rename('nmiss')).rename_axis('feature').reset_index()\n",
    "print(f\"Validation Variables having missing values: {nmiss_val_df[nmiss_val_df['nmiss']>0].index.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70fb730f-9eb7-47a8-b0ca-31a0d08de90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Pickle Model Data\n",
    "model_data_pckl_dict['dev_data_dummy'] = dev_data_dummy\n",
    "model_data_pckl_dict['val_data_dummy'] = val_data_dummy\n",
    "\n",
    "# Update Pickle Metadata\n",
    "model_metadata_pckl_dict['d_ord_enc'] = d_ord_enc\n",
    "model_metadata_pckl_dict['d_oh_enc'] = d_oh_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169b7ae4-f165-4585-bf85-afb294c7cf7c",
   "metadata": {},
   "source": [
    "<h4> 3.6 Export Fine Classing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20f4cfdb-201e-4939-a4e4-38a648ced3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Pickle Metadata\n",
    "model_metadata_pckl_dict['c_class_df'] = coarse_classing_df\n",
    "model_metadata_pckl_dict['f_class_df'] = fine_classing_df\n",
    "\n",
    "# Save Model data\n",
    "with open(f'{outpath}/model_data.pickle', 'wb') as f:\n",
    "    pickle.dump(model_data_pckl_dict, f)\n",
    "    \n",
    "# Save Model Metadata\n",
    "with open(f'{outpath}/model_metadata.pickle', 'wb') as f:\n",
    "    pickle.dump(model_metadata_pckl_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f1a8855-0f78-47e6-8020-386b9ab5af78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 s, sys: 1.95 s, total: 16.6 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Export Fine Classing Output\n",
    "export_fine_classing_data(fine_classing_df.drop(['bin_left', 'bin_right'], axis=1), outpath, f\"{dev_fname.split('.')[0]}_fine_classing.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
