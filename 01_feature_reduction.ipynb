{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49bfccee-789c-415e-9790-92a9738ffed6",
   "metadata": {},
   "source": [
    "#### Module Summary\n",
    "\n",
    "> This module reduces input features using the below set of checks on the data -\n",
    "> 1. Drop features with > 95% missing values\n",
    "> 2. Drop Degenrate features (only one value)\n",
    "> 3. Drop features with > 90% correlation with other features\n",
    "> 4. Drop features with high data drift (CSI > 25%)\n",
    ">\n",
    "> The module also performs an Exploratory Data Analysis and some basic data preparations like removing leading and trailing blanks, data type transformations, handling special values, missing value imputation etc.\n",
    ">\n",
    "> **Input Files**\n",
    ">   1. Development Data (csv)\n",
    ">   2. Validation Data (csv)\n",
    ">\n",
    "> **Output Files**\n",
    ">   1. Development & Validation Data with reduced features (pickle)\n",
    ">   2. Feature Reduction Summary (excel)\n",
    ">   3. Model metadata - will be required for scoring (pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ead6f-dd13-457e-9fe2-42bd4759ddf3",
   "metadata": {},
   "source": [
    "<h4> 1.1 Import Libraries & Parameters and Initialise Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d1c642-6687-4c36-b270-e411c09d5325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and Parameters\n",
    "import logit_config as cfg\n",
    "exec(open('module_imports.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86db3c14-74fb-4c32-84ae-db0e70ecc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete All Output Files\n",
    "out_flist = glob.glob(f\"{outpath}/*.csv\") + glob.glob(f\"{outpath}/*.xlsx\") + glob.glob(f\"{outpath}/*.pickle\") + glob.glob(f\"{outpath}/*.aes\") + glob.glob(f\"{outpath}/**/*.png\", recursive=True) + glob.glob(f\"{outpath}/*.html\")\n",
    "for f in out_flist:\n",
    "    os.remove(f)\n",
    "    \n",
    "# Create Graph Folder\n",
    "if not(os.path.exists(f\"{outpath}/graph\")):\n",
    "    os.mkdir(f\"{outpath}/graph\")\n",
    "    \n",
    "# Initialise Output Files\n",
    "create_empty_excel_template(f'{outpath}/{feature_reduction_outfile}', ['Drop Reason Summary', 'Missing %', 'Correlation', 'Data Drift', 'Information Value', 'RFE', 'Stepwise Logistic'])\n",
    "\n",
    "# Initialise list of Variables to retaine\n",
    "retain_var_list = id_varlist + [resp_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d04272d-8936-466b-9e2a-a637822e3565",
   "metadata": {},
   "source": [
    "<h4> 1.2 Data Import and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1560bbf8-aa3d-43e0-b2dd-179f0bd62354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development & Validation data have the same columns\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "dev_data = pd.read_csv(f\"{fpath}/{dev_fname}\", thousands=',')\n",
    "val_data = pd.read_csv(f\"{fpath}/{val_fname}\", thousands=',')\n",
    "\n",
    "# Data Consistency Check\n",
    "char_col_list = [x for x in dev_data.select_dtypes(exclude=np.number).columns if x not in non_pred_varlist+drop_varlist]\n",
    "val_extra_col_df = check_data_consistency(dev_data, val_data, char_col_list)\n",
    "val_extra_col_df.to_csv(f\"{outpath}/val_extra_val_mapping.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b747bfc6-6c1d-407a-b123-46ab2ff40c7b",
   "metadata": {},
   "source": [
    "<font color=blue>The above section will export a csv file @ **.out/val_extra_val_mapping.csv**\\\n",
    "This lists out all categorical variables with 'new' values in validation dataset, that do not appear in the development data. All these values will be made missing values in the next step. Please make changes to the above file if necessary, before running the replace new values in validation data module.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc3e341-c66e-4276-9029-1291b94e58a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace New Classes (classes that appear in val data but not in dev data) of categorical variables in Validation Data\n",
    "val_extra_col_df = pd.read_csv(f\"{outpath}/val_extra_val_mapping.csv\")\n",
    "val_remap_dict = {col: {r.Values: r['Replace Value'] for i, r in val_extra_col_df[val_extra_col_df['Variable'] == col].iterrows()} for col in val_extra_col_df['Variable'].unique()}\n",
    "val_data = val_data.replace(val_remap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607ef274-082b-46db-9629-b15157012682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development Data Shape: (341, 32)\n",
      "Development Response Rate: 36.66%\n",
      "Validation Data Shape: (228, 32)\n",
      "Validation Response Rate: 38.16%\n"
     ]
    }
   ],
   "source": [
    "# Drop Unnecessary Variables and convert variable types\n",
    "dev_data = pre_process_data(dev_data, drop_varlist)\n",
    "val_data = pre_process_data(val_data, drop_varlist)\n",
    "\n",
    "print(f\"Development Data Shape: {dev_data.shape}\\nDevelopment Response Rate: {np.round(dev_data[resp_var].mean()*100, 2)}%\")\n",
    "try:\n",
    "    print(f\"Validation Data Shape: {val_data.shape}\\nValidation Response Rate: {np.round(val_data[resp_var].mean()*100, 2)}%\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Copy dtype of Dev Data to Validation Data\n",
    "dev_dtypes_dict = dev_data.dtypes.to_dict()\n",
    "val_data = val_data.astype({key: dev_dtypes_dict[key] for key in val_data.columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa6ba9-a108-4008-8fd6-b3de9a652c36",
   "metadata": {},
   "source": [
    "<h4> 1.3 Missing Value & Degenrate Value Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa86be3-0a3e-413a-9405-198498917eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Value cut-off being used: 0.95. Variables dropped: 0\n",
      "Degenerate Variables (Variables having only one value) Dropped: 0\n",
      "Updated Development Data Shape: (341, 32)\n"
     ]
    }
   ],
   "source": [
    "dev_data, val_data, nmiss_data, drop_reason_data = nmiss_nunique_check(dev_data, val_data)\n",
    "print(f\"Updated Development Data Shape: {dev_data.shape}\")\n",
    "\n",
    "export_data_to_excel(nmiss_data, f'{outpath}/{feature_reduction_outfile}', sheetName='Missing %', pct_col_list=['dev_miss_pct', 'val_missing_pct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f7b67-ff70-433b-99b5-e9e82bbcd755",
   "metadata": {},
   "source": [
    "<h4> 1.4 Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f34808-d3e9-42a7-9a87-8251255ccdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_RFE_ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422cc00-68bf-4da3-ae5c-4758e61cc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if execc_RFE_ind == 1:\n",
    "    \n",
    "    # Compute RFE List\n",
    "    varlist = [x for x in dev_data.columns if x not in non_pred_varlist]\n",
    "    RFE_varlist = get_RFE_features(dev_data.copy(), varlist, resp_var, n_features=50)\n",
    "    retain_var_list = retain_var_list + RFE_varlist\n",
    "\n",
    "    # Export Data\n",
    "    RFE_df = pd.DataFrame(RFE_varlist, columns=['feature'])\n",
    "    export_data_to_excel(RFE_df, feature_reduction_outfile, sheetName='RFE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482fd10-6329-4ccd-992d-94379996a737",
   "metadata": {},
   "source": [
    "<h4> 1.5 Correlation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad6568b-a2e5-45ab-ad78-c62af1a05b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation cut-off being used: 0.9\n",
      "Variables Dropped: 22\n",
      "Updated Development Data Shape: (341, 21)\n",
      "CPU times: user 119 ms, sys: 12.8 ms, total: 132 ms\n",
      "Wall time: 162 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Check Correlation\n",
    "corr_check_df = corr_check(dev_data.drop(id_varlist, axis=1), resp_var, corr_cutoff)\n",
    "corr_check_df['corr_val'] = corr_check_df['corr_val'].apply(lambda x: np.round(x, 4))\n",
    "\n",
    "# Drop Features with high correlation\n",
    "corr_drop_varlist = [x for x in corr_check_df['del_var'].tolist() if x not in retain_var_list]\n",
    "dev_data.drop(corr_drop_varlist, axis=1, inplace=True)\n",
    "print(f\"Correlation cut-off being used: {corr_cutoff}\\nVariables Dropped: {len(corr_drop_varlist)}\\nUpdated Development Data Shape: {dev_data.shape}\")\n",
    "\n",
    "# Export Variable Dropout Reason\n",
    "export_data_to_excel(corr_check_df, f'{outpath}/{feature_reduction_outfile}', sheetName='Correlation', pct_col_list='corr_val')\n",
    "corr_check_df['drop_reason'] = 'high_correlation'\n",
    "drop_reason_data = drop_reason_data.append(corr_check_df[['del_var', 'drop_reason']].rename(columns={'del_var': 'feature'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d88de2-71b9-4068-ad4f-d18de094a7aa",
   "metadata": {},
   "source": [
    "<h4> 1.6 EDA, Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "596dd1bb-9588-4f49-bede-1b3999f265bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c471b8fb7284b00b63c7c56897a7a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d701c6f520427ab27ad27a67b95eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5777468e0c4d9e802f94fc1f09f1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0164930795bb4192a5605cfee1836288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 6.54 s, total: 1min 55s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Exploratory Analysis\n",
    "profile = ProfileReport(dev_data, title=\"Pandas Profiling Report\", explorative=True)\n",
    "profile.to_file(f'{outpath}/eda_pandas_profiling.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d39d7f8-ff6f-4b53-82d0-0e3c6d2c7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Analysis\n",
    "EDA_df = get_exploratory_analysis(dev_data, [x for x in dev_data.columns if x not in non_pred_varlist])\n",
    "EDA_df.fillna('').to_csv(f'{outpath}/exploratory_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6ba3d11-951c-494d-bd5d-867b3d0659b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Default Missing Value Imputation Input Data\n",
    "dtypes_df = create_mv_impute_input(dev_data.drop(non_pred_varlist, axis=1))\n",
    "dtypes_df.to_csv(f'{outpath}/{mv_input}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0021e9-27af-4165-98f8-68b97630780c",
   "metadata": {},
   "source": [
    "<font color=blue>The above section exports a csv file @ **.out/missing_value_imputation_input.csv**\\\n",
    "This will be used as an input to the missing value imputation module in the below section. Please review and make changes to the above csv file, if necessary, before running the missing value imputation module below.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ed44d2f-296d-442e-a23a-ffd64921a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Value Imputation\n",
    "imp_df = pd.read_csv(f'{outpath}/{mv_input}')\n",
    "dev_data = impute_missing_values(dev_data, imp_df)\n",
    "val_data = impute_missing_values(val_data, imp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4eb8bf-216f-4dd6-9ec8-7badf107a8ca",
   "metadata": {},
   "source": [
    "<h4> 1.6 Data Drift Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea56bad2-70a6-4519-8ebf-8644de000912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSI cut-off being used: 0.25\n",
      "Variables Dropped: 1\n",
      "Updated Development Data Shape: (341, 20)\n"
     ]
    }
   ],
   "source": [
    "# Compute CSI\n",
    "csi_df = compute_csi(dev_data, val_data, resp_var, id_varlist)\n",
    "csi_drop_var_df = csi_df[csi_df['CSI'] >= csi_cutoff]\n",
    "\n",
    "# Drop Variables\n",
    "csi_drop_varlist = [x for x in csi_drop_var_df['feature'].tolist() if x not in retain_var_list]\n",
    "dev_data.drop(csi_drop_varlist, axis=1, inplace=True)\n",
    "print(f\"CSI cut-off being used: {csi_cutoff}\\nVariables Dropped: {len(csi_drop_varlist)}\\nUpdated Development Data Shape: {dev_data.shape}\")\n",
    "\n",
    "# Export Variable Dropout Reason\n",
    "csi_drop_var_df['drop_reason'] = 'high_data_drift'\n",
    "drop_reason_data = drop_reason_data.append(csi_drop_var_df[['feature', 'drop_reason']])\n",
    "export_data_to_excel(csi_df, f'{outpath}/{feature_reduction_outfile}', sheetName='Data Drift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f94a984-ba33-4cd0-a2c5-96df52ea8bb7",
   "metadata": {},
   "source": [
    "<h4> 1.7 Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "687049aa-637e-4386-86db-ec428a2a4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Reduction Summary\n",
    "export_data_to_excel(drop_reason_data, f'{outpath}/{feature_reduction_outfile}', sheetName='Drop Reason Summary')\n",
    "\n",
    "# Save Updated Dev & Val Data\n",
    "with open(f\"{outpath}/model_data.pickle\", 'wb') as f:\n",
    "    pickle.dump({'dev_data_out1': dev_data, 'val_data_out1': val_data[dev_data.columns.tolist()]}, f)\n",
    "    \n",
    "# Save Model Metadata\n",
    "with open(f\"{outpath}/model_metadata.pickle\", 'wb') as f:\n",
    "    pickle.dump({'dev_dtypes_dict': dev_dtypes_dict, 'imp_df': imp_df}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
