{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c973bc64-ce3a-4b70-bb75-cd21917f6aa0",
   "metadata": {},
   "source": [
    "#### Module Summary\n",
    "\n",
    "> This module will be used for scoring a data using the logit model post implementation. The module will take care of the data preprocessing and data conversion before scoring\n",
    ">\n",
    "> **Input Files**\n",
    "> 1. Scoring Data (csv)\n",
    "> 2. Scoring pickle file - model metadata (pickle)\n",
    ">\n",
    "> **Output Files**\n",
    "> Scored Output with ML Score (csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def9dcf3-38f1-4ca0-af09-2a49ccfe4627",
   "metadata": {},
   "source": [
    "<h4> 5.1 Import Modules and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b50fd5-4c9d-4d17-889b-6c48786e75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import warnings, time, pickle, math, statistics, os\n",
    "import logit_config as cfg\n",
    "from pdLogit.data_processing import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Location Parameters\n",
    "wpath = cfg.wpath\n",
    "fpath = wpath + '/data'\n",
    "outpath = wpath + '/out'\n",
    "\n",
    "# Data Related Parameters\n",
    "score_fname = 'test_data.csv'\n",
    "resp_var = cfg.resp_var\n",
    "id_varlist = cfg.id_varlist\n",
    "drop_varlist = cfg.drop_varlist\n",
    "non_pred_varlist = id_varlist + [resp_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87178585-2f0a-4650-aa85-a587f74db055",
   "metadata": {},
   "source": [
    "<h4> 5.2 Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "509f3ad6-2087-43cc-8a68-87f9784ffe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Data Shape: (228, 32)\n"
     ]
    }
   ],
   "source": [
    "# Import Scoring Data\n",
    "scoring_data = pd.read_csv(f'{fpath}/{score_fname}')\n",
    "print(f'Scoring Data Shape: {scoring_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91de2402-3dd2-4957-9776-e5837864329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Model Metadata\n",
    "with open(f\"{outpath}/model_metadata.pickle\", 'rb') as f:\n",
    "    pickle_dict = pickle.load(f)\n",
    "dev_dtypes_dict = pickle_dict['dev_dtypes_dict']\n",
    "imp_df = pickle_dict['imp_df']\n",
    "c_class_df = pickle_dict['c_class_df']\n",
    "f_class_df = pickle_dict['f_class_df']\n",
    "logit_model_obj = pickle_dict['model']\n",
    "model_approach = pickle_dict['model_approach']\n",
    "\n",
    "if model_approach == 'dummy_vars':\n",
    "    d_ord_enc = pickle_dict['d_ord_enc']\n",
    "    d_oh_enc = pickle_dict['d_oh_enc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05693102-a37b-4287-9a66-c4b73f05d75d",
   "metadata": {},
   "source": [
    "<h4> 5.3 Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5799988c-74d7-44ed-8595-334f328ef366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Data Shape: (228, 10)\n"
     ]
    }
   ],
   "source": [
    "# Remove Leading and Trailing Blanks\n",
    "scoring_data = pre_process_data(scoring_data, drop_varlist)\n",
    "\n",
    "# Get Model Variables\n",
    "if model_approach == 'woe':\n",
    "    model_varlist = list(set([x[2:] for x in logit_model_obj.params.index.tolist() if x != 'const']))\n",
    "elif model_approach == 'dummy_vars':\n",
    "    model_varlist = list(set([x.replace('_'+x.split('_')[-1], '')[2:] for x in logit_model_obj.params.index.tolist() if x != 'const']))\n",
    "    \n",
    "# Convert Boolean Variables to Character\n",
    "bool_varlist = [x for x in scoring_data.columns if scoring_data[x].dtypes.kind == 'b']\n",
    "for var in bool_varlist:\n",
    "    scoring_data[var] = scoring_data[var].astype(str)\n",
    "    \n",
    "# Create Variable Lists\n",
    "char_varlist = [x for x in model_varlist if dev_dtypes_dict[x] == object]\n",
    "num_varlist = [x for x in model_varlist if x not in char_varlist]\n",
    "\n",
    "# Keep Required Columns only\n",
    "keep_varlist = id_varlist + model_varlist\n",
    "scoring_X = scoring_data[keep_varlist]\n",
    "\n",
    "print(f'Scoring Data Shape: {scoring_X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ad5fa1a-4f43-4ef4-9565-39207365e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace New Values with Missing\n",
    "for col in char_varlist:\n",
    "    scoring_X.loc[~scoring_X[col].isin(c_class_df[c_class_df['VAR_NAME'] == col]['VAR_BINS']), col] = np.nan\n",
    "\n",
    "# Copy Dev Data Types to Scoring Data\n",
    "# scoring_X = copy_dtypes(dev_dtypes_dict, scoring_X)\n",
    "scoring_X = scoring_X.astype({key: dev_dtypes_dict[key] for key in scoring_X.columns})\n",
    "\n",
    "# Missing Value Imputation\n",
    "scoring_X = impute_missing_values(scoring_X, imp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cde50aa-1e9c-4026-bc7f-7b2252aa5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric Variables\n",
    "f_class_df = f_class_df[['VAR_NAME', 'VAR_BINS', 'LN_ODDS', 'bin_left', 'bin_right']]\n",
    "for col in num_varlist:\n",
    "    \n",
    "    var_df = f_class_df[f_class_df['VAR_NAME'] == col]\n",
    "    \n",
    "    # Create Cutpoints List\n",
    "    cutpoints = var_df['bin_left'].tolist() + var_df['bin_right'].tolist()\n",
    "    cutpoints = list(set(cutpoints))\n",
    "    cutpoints.sort()\n",
    "    \n",
    "    # Update Original Variable with Bin Value - Development\n",
    "    scoring_X[col] = scoring_X[col].astype(float)\n",
    "    scoring_X['var_bin_lat'] = pd.cut(scoring_X[col], cutpoints, right=True, labels=None, retbins=False, precision=10, include_lowest=False)\n",
    "    scoring_X.drop(col, axis=1, inplace=True)\n",
    "    scoring_X.rename(columns={'var_bin_lat': col}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa951e0-af95-4a89-8ba3-b3ff11644ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character Variables\n",
    "c_class_df = c_class_df[c_class_df['VAR_NAME'].isin(char_varlist)]\n",
    "for col in char_varlist:\n",
    "    var_df = c_class_df[c_class_df['VAR_NAME'] == col][['VAR_BINS', 'FINE_BIN_NUM']]\n",
    "    scoring_X[col] = scoring_X[col].astype(str)\n",
    "    scoring_X = scoring_X.merge(var_df, left_on=col, right_on='VAR_BINS', how='left')\n",
    "    scoring_X.drop([col, 'VAR_BINS'], axis=1, inplace=True)\n",
    "    scoring_X.rename(columns={'FINE_BIN_NUM': col}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd13b12-98ce-479d-b64d-3f222cb0a7fe",
   "metadata": {},
   "source": [
    "<h4> 5.4 WOE Value Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc18bda1-fa64-4f82-a9fc-4f2311fdda6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables having Missing Values: 0\n"
     ]
    }
   ],
   "source": [
    "if model_approach == 'woe':\n",
    "    \n",
    "    # Replace Original Data with WOE Values\n",
    "    for col in model_varlist:\n",
    "        \n",
    "        _woe_df = f_class_df[f_class_df['VAR_NAME'] == col][['VAR_BINS', 'LN_ODDS']]\n",
    "        _woe_df['VAR_BINS'] = _woe_df['VAR_BINS'].astype(str)\n",
    "        scoring_X[col] = scoring_X[col].astype(str)\n",
    "        scoring_X = scoring_X.merge(_woe_df, left_on=col, right_on='VAR_BINS', how='left')\n",
    "        scoring_X.drop([col, 'VAR_BINS'], axis=1, inplace=True)\n",
    "        scoring_X.rename(columns={'LN_ODDS': 'L_'+col}, inplace=True)\n",
    "        \n",
    "    model_varlist_L = ['L_'+x for x in model_varlist]\n",
    "    scoring_X_enc_df = scoring_X[model_varlist_L]\n",
    "    \n",
    "    # Check for Missing Values\n",
    "    nmiss_score_df = pd.DataFrame(scoring_X_enc_df.isnull().sum().rename('nmiss').rename_axis('feature')).reset_index()\n",
    "    nmiss_score = nmiss_score_df[nmiss_score_df['nmiss'] > 0].index.size\n",
    "    print(f'Variables having Missing Values: {nmiss_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be999624-239e-4656-829c-a706f46ca62c",
   "metadata": {},
   "source": [
    "<h4> 5.5 Dummy Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec565e5-a50a-4acb-9326-7b7ef7b979a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_approach == 'dummy_vars':\n",
    "    \n",
    "    varList = [x for x in scoring_X.columns if x not in non_pred_varlist]\n",
    "    \n",
    "    # Ordinal Encoder Preprocessor\n",
    "    d_ord_enc = {k: v for k, v in d_ord_enc.items() if k in scoring_X.columns}\n",
    "    scoring_X[list(d_ord_enc.keys())] = pd.DataFrame({col: scoring_X[col].map(d_ord_enc[col]).fillna(statistics.mode(d_ord_enc[col].values())) for col in d_ord_enc.keys()})\n",
    "    \n",
    "    # One-Hot Encoding to Create Dummy Variables\n",
    "    oh_extra_cols_df = pd.DataFrame({x: ['d0']*scoring_X.index.size for x in d_oh_enc.feature_names_in_ if x not in scoring_X.columns})\n",
    "    oh_input_df = pd.concat([scoring_X, oh_extra_cols_df], axis=1).drop(id_varlist, axis=1)[list(d_oh_enc.feature_names_in_)]\n",
    "    scoring_X_enc_df_all = pd.DataFrame(d_oh_enc.transform(oh_input_df).toarray())\n",
    "    scoring_X_enc_df_all.columns = ['L_'+x for x in d_oh_enc.et_feature_names_out().tolist()]\n",
    "    \n",
    "    # Finalise Model Variables\n",
    "    model_varlist = [x for x in logit_model_obj.params.index.tolist() if x != 'const']\n",
    "    scoring_X_enc_df = scoring_X_enc_df_all[model_varlist]\n",
    "    \n",
    "    # Check for Missing Values\n",
    "    nmiss_score_df = pd.DataFrame(scoring_X_enc_df.isnull().sum().rename('nmiss').rename_axis('feature')).reset_index()\n",
    "    nmiss_score = nmiss_score_df[nmiss_score_df['nmiss'] > 0].index.size\n",
    "    print(f'Variables having Missing Values: {nmiss_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3240ffc3-431c-4aeb-ab87-329f5610a15d",
   "metadata": {},
   "source": [
    "<h4> 5.6 Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a97df18-2f43-4d4f-a21e-4bcd247810b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>odds</th>\n",
       "      <th>scaled_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842517.0</td>\n",
       "      <td>0.249749</td>\n",
       "      <td>0.332888</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84300903.0</td>\n",
       "      <td>0.978462</td>\n",
       "      <td>45.429622</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84348301.0</td>\n",
       "      <td>0.960140</td>\n",
       "      <td>24.087493</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84358402.0</td>\n",
       "      <td>0.980711</td>\n",
       "      <td>50.841791</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843786.0</td>\n",
       "      <td>0.043532</td>\n",
       "      <td>0.045513</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  Prediction       odds  scaled_score\n",
       "0    842517.0    0.249749   0.332888           348\n",
       "1  84300903.0    0.978462  45.429622           136\n",
       "2  84348301.0    0.960140  24.087493           163\n",
       "3  84358402.0    0.980711  50.841791           131\n",
       "4    843786.0    0.043532   0.045513           434"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Intercept Column\n",
    "scoring_X_enc_df['const'] = 1\n",
    "\n",
    "# Score\n",
    "scoring_X_enc_df['Prediction'] = logit_model_obj.predict(scoring_X_enc_df)\n",
    "scoring_X_enc_df['odds'] = scoring_X_enc_df['Prediction'].apply(lambda x: x/(1-x) if x < 1 else x/(1-x+0.00001))\n",
    "scoring_X_enc_df['scaled_score'] = scoring_X_enc_df['odds'].apply(lambda x: int(np.round(500-30*(math.log10(100)/math.log10(2))-(30*math.log10(x)/math.log10(2)))))\n",
    "scoring_X_enc_df = scoring_X_enc_df.drop(logit_model_obj.params.index.tolist(), axis=1)\n",
    "\n",
    "scoring_data_out = pd.concat([scoring_data[id_varlist], scoring_X_enc_df], axis=1)\n",
    "scoring_data_out.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
